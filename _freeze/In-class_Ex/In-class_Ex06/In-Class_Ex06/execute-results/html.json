{
  "hash": "83dda0c37d23a3f2ed878d96e29965ad",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"In Class Exercise 6\"\nauthor: \"Georgia Ng\"\ndate: \"September 23, 2024\"\ndate-modified: \"last-modified\"\nexecute: \n  eval: true\n  echo: true\n  warning: false\n  freeze: true\n---\n\n\n## 6.0 Overview\n\nSpatial autocorrelation: term used to describe the presence of systematic spatial variation in a variable.\n\nMore negative correlation = more outliers (with a checkboard pattern)\n\nMoran's I (z value): Describe how features differ from the values in the study area as a whole\n\n-   Positive value: Clustered, observations tend to be similar\n\n-   Negative value: Dispersed, observations tend to be dissimilar\n\n-   Approx. zero: Observations are arranged randomly over space\n\nGeary c (z value): Describe how features different from their immediate neighbours\n\n-   Positive value: Dispersed, observations tend to be dissimilar\n\n-   Negative value: Clustered, observations tend to be similar\n\n-   c=1: observations are arranged randomly over space\n\nConfidence interval: value in which represents how confident you are, recommended to be 95%\n\n## 6.1 Installing Packages\n\nIn this in class exercise, we will be using the following packages:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, sfdep, tmap, tidyverse)\n```\n:::\n\n\n## 6.2 The Data\n\n### 6.2.1 Import shapefile into r environment\n\nThe code chunk below uses [*st_read()*](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import Hunan shapefile into R. The imported shapefile will be **simple features** Object of **sf**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Hunan' from data source \n  `/Users/georgiaxng/georgiaxng/is415-handson/In-class_Ex/In-class_Ex06/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n:::\n\n\n### 6.2.2 Import csv file into r environment\n\nNext, we will import *Hunan_2012.csv* into R by using *read_csv()* of **readr** package. The output is R dataframe class.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n```\n:::\n\n\n### 6.2.3 Performing relational join\n\nThe code chunk below will be used to update the attribute table of *hunan*’s SpatialPolygonsDataFrame with the attribute fields of *hunan2012* dataframe. This is performed by using *left_join()* of **dplyr** package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_GDPPC <- left_join(hunan,hunan2012)%>%\n  select(1:4,7,15)\n```\n:::\n\n\n### 6.2.4 Plotting Chloropeth Map\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by county, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n```\n\n::: {.cell-output-display}\n![](In-Class_Ex06_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n## 6.3 Global Measures of Spatial Association \n\n### 6.3.1 Deriving contiguity weights: Queen's method\n\nNote: nb refers to the neighbours\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_q <- hunan_GDPPC %>% mutate(nb = st_contiguity(geometry), \n                               wt = st_weights(nb, style = \"W\"), \n                               .before = 1)\n```\n:::\n\n\n### 6.3.2 Computing Global Moran's I \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmoranI<- global_moran(wm_q$GDPPC,\n                      wm_q$nb,\n                      wm_q$wt)\nglimpse(moranI)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n```\n\n\n:::\n:::\n\n\n::: callout-tip\nK refers to average neighbours they have\n:::\n\n### 6.3.3 Performing Global Moran's I Test\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_moran_test(wm_q$GDPPC,\n                      wm_q$nb,\n                      wm_q$wt)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMoran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n```\n\n\n:::\n:::\n\n\n### 6.3.4 Performing Global Moran's I permutation test\n\nIn practice, monte carlo simulation should be used to perform the statistical test. For **sfdep**, it is supported by [`globel_moran_perm()`](https://sfdep.josiahparry.com/reference/global_moran_perm.html)\n\nIt is alway a good practice to use `set.seed()` before performing simulation. This is to ensure that the computation is reproducible.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n```\n:::\n\n\nNext, `global_moran_perm()` is used to perform Monte Carlo simulation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_moran_perm(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt,\n                  nsim = 99)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMonte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n\nThe statistical report above show that the p-value is smaller than alpha value of 0.05. Hence, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of GPD per capita are resemble random distribution (i.e. independent from spatial). Because the Moran's I statistics is greater than 0. We can infer that the spatial distribution shows sign of clustering.\n\n::: callout-tip\nThe numbers of simulation is alway equal to nsim + 1. This mean in nsim = 99. This mean 100 simulation will be performed.\n:::\n\n## 6.4 Computing Local Moran's I & Visualisations\n\nIn this section, we will learn how to compute Local Moran's I of GDPPC at county level by using [`local_moran()`](https://sfdep.josiahparry.com/reference/local_moran.html) of sfdep package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa <- wm_q %>% \n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_moran)\n```\n:::\n\n\n::: callout-note\n-   unnest is to put it back to one single tibble table\n\n-   To ensure consistency, stay with one p value (either p_ii_sim or p_folded sim(k4))\n\n-   If skewness is close to 0, use mean, else, use median.\n\nThe output of `local_moran()` is a sf data.frame containing the columns ii, eii, var_ii, z_ii, p_ii, p_ii_sim, and p_folded_sim.\n\n-   ii: local moran statistic\n-   eii: expectation of local moran statistic; for localmoran_permthe permutation sample means\n-   var_ii: variance of local moran statistic; for localmoran_permthe permutation sample standard deviations\n-   z_ii: standard deviate of local moran statistic; for localmoran_perm based on permutation sample means and standard deviations p_ii: p-value of local moran statistic using pnorm(); for localmoran_perm using standard deviatse based on permutation sample means and standard deviations p_ii_sim: For `localmoran_perm()`, `rank()` and `punif()` of observed statistic rank for \\[0, 1\\] p-values using `alternative=` -p_folded_sim: the simulation folded \\[0, 0.5\\] range ranked p-value (based on <https://github.com/pysal/esda/blob/4a63e0b5df1e754b17b5f1205b> cadcbecc5e061/esda/crand.py#L211-L213)\n-   skewness: For `localmoran_perm`, the output of e1071::skewness() for the permutation samples underlying the standard deviates\n-   kurtosis: For `localmoran_perm`, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates.\n:::\n\n### 6.4.1 Visualising local Moran's I\n\nIn this code chunk below, tmap functions are used prepare a choropleth map by using value in the *ii* field.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n```\n\n::: {.cell-output-display}\n![](In-Class_Ex06_files/figure-html/unnamed-chunk-12-1.png){width=768}\n:::\n:::\n\n\n### 6.4.2 Visualising p-value of local Moran's I\n\nIn the code chunk below, tmap functions are used prepare a choropleth map by using value in the *p_ii_sim* field.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") + \n  tm_borders(alpha = 0.5) +\n   tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n```\n\n::: {.cell-output-display}\n![](In-Class_Ex06_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n::: callout-warning\nFor p-values, the appropriate classification should be 0.001, 0.01, 0.05 and not significant instead of using default classification scheme.\n:::\n\n### 6.4.3 Visualising local Moran's I and p-value\n\nFor effective comparison, it will be better for us to plot both maps next to each other as shown below.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\ntmap_mode(\"plot\")\nmap1 <- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 <- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](In-Class_Ex06_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n### 6.4.4 Visualising LISA map\n\nLISA map is a categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two type of clusters namely: High-High and Low-Low cluaters. In fact, LISA map is an interpreted map by combining local Moran's I of geographical areas and their respective p-values.\n\nIn lisa sf data.frame, we can find three fields contain the LISA categories. They are *mean*, *median* and *pysal*. In general, classification in *mean* will be used as shown in the code chunk below.\n\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa_sig <- lisa  %>%\n  filter(p_ii < 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n```\n\n::: {.cell-output-display}\n![](In-Class_Ex06_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n:::\n\n## 6.5 Hot Spot and Cold Spot Area Analysis (HCSA)\n\nHCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in an spatially weighted attribute that are in proximity to one another based on a calculated distance. The analysis groups features when similar high (hot) or low (cold) values are found in a cluster. The polygon features usually represent administration boundaries or a custom grid structure.\n\n## 6.6 Computing local Gi\\* statistics\n\nAs usual, we will need to derive a spatial weight matrix before we can compute local Gi\\* statistics. Code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_idw <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n```\n:::\n\n\n::: callout-note\nGi\\* and local Gi\\* are distance-based spatial statistics. Hence, distance methods instead of contiguity methods should be used to derive the spatial weight matrix.\n:::\n\nNow, we will compute the local Gi\\* by using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nHCSA <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\nHCSA\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n   gi_star cluster   e_gi     var_gi std_dev p_value p_sim p_folded_sim skewness\n     <dbl> <fct>    <dbl>      <dbl>   <dbl>   <dbl> <dbl>        <dbl>    <dbl>\n 1  0.0416 Low     0.0114 0.00000641  0.0493 9.61e-1  0.7          0.35    0.875\n 2 -0.333  Low     0.0106 0.00000384 -0.0941 9.25e-1  1            0.5     0.661\n 3  0.281  High    0.0126 0.00000751 -0.151  8.80e-1  0.9          0.45    0.640\n 4  0.411  High    0.0118 0.00000922  0.264  7.92e-1  0.6          0.3     0.853\n 5  0.387  High    0.0115 0.00000956  0.339  7.34e-1  0.62         0.31    1.07 \n 6 -0.368  High    0.0118 0.00000591 -0.583  5.60e-1  0.72         0.36    0.594\n 7  3.56   High    0.0151 0.00000731  2.61   9.01e-3  0.06         0.03    1.09 \n 8  2.52   High    0.0136 0.00000614  1.49   1.35e-1  0.2          0.1     1.12 \n 9  4.56   High    0.0144 0.00000584  3.53   4.17e-4  0.04         0.02    1.23 \n10  1.16   Low     0.0104 0.00000370  1.82   6.86e-2  0.12         0.06    0.416\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis <dbl>, nb <nb>, wts <list>, NAME_2 <chr>,\n#   ID_3 <int>, NAME_3 <chr>, ENGTYPE_3 <chr>, County <chr>, GDPPC <dbl>,\n#   geometry <POLYGON [°]>\n```\n\n\n:::\n:::\n\n\n### 6.6.1 Visualising Gi\\*\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n```\n\n::: {.cell-output-display}\n![](In-Class_Ex06_files/figure-html/unnamed-chunk-18-1.png){width=768}\n:::\n:::\n\n\n### 6.6.2 Visualising p-value of HCSA\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)\n```\n\n::: {.cell-output-display}\n![](In-Class_Ex06_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n### 6.6.3 Visualising local HCSA\n\nFor effective comparison, you can plot both maps next to each other as shown below.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\ntmap_mode(\"plot\")\nmap1 <- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 <- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](In-Class_Ex06_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n## 7 Visualising hot spot and cold spot areas\n\nNow, we are ready to plot the significant (i.e. p-values less than 0.05) hot spot and cold spot areas by using appropriate tmap functions as shown below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nHCSA_sig <- HCSA  %>%\n  filter(p_sim < 0.05)\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.4)\n```\n\n::: {.cell-output-display}\n![](In-Class_Ex06_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\nFigure above reveals that there is one hot spot area and two cold spot areas. Interestingly, the hot spot areas coincide with the High-high cluster identifies by using local Moran's I method in the earlier sub-section.\n",
    "supporting": [
      "In-Class_Ex06_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}