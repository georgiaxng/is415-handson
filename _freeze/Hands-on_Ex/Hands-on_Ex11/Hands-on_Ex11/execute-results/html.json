{
  "hash": "ee366eebea6ce148f2f56623a0245825",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hands-On Exercise 11: Geographically Weighted Predictive Models\"\nauthor: \"Georgia Ng\"\ndate: \"October 31, 2024\"\ndate-modified: \"last-modified\"\nexecute: \n  eval: true\n  echo: true\n  warning: false\n  freeze: true\n  cache: true\n---\n\n\n## 11.1 Overview\n\nPredictive modelling uses statistical learning or machine learning techniques to predict outcomes. By and large, the event one wants to predict is in the future. However, a set of known outcome and predictors (also known as variables) will be used to calibrate the predictive models.\n\nGeospatial predictive modelling is conceptually rooted in the principle that the occurrences of events being modeled are limited in distribution. When geographically referenced data are used, occurrences of events are neither uniform nor random in distribution over space. There are geospatial factors (infrastructure, sociocultural, topographic, etc.) that constrain and influence where the locations of events occur. Geospatial predictive modeling attempts to describe those constraints and influences by spatially correlating occurrences of historical geospatial locations with environmental factors that represent those constraints and influences.\n\n### 11.1.1 Learning outcome\n\nIn this in-class exercise, you will learn how to build predictive model by using geographical random forest method. By the end of this hands-on exercise, you will acquire the skills of:\n\n-   preparing training and test data sets by using appropriate data sampling methods,\n-   calibrating predictive models by using both geospatial statistical learning and machine learning methods,\n-   comparing and selecting the best model for predicting the future outcome,\n-   predicting the future outcomes by using the best model calibrated.\n\n## 11.2 The Data\n\n-   **Aspatial dataset**:\n    -   HDB Resale data: a list of HDB resale transacted prices in Singapore from Jan 2017 onwards. It is in csv format which can be downloaded from Data.gov.sg.\n-   **Geospatial dataset**:\n    -   *MP14_SUBZONE_WEB_PL*: a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg\n-   **Locational factors with geographic coordinates**:\n    -   Downloaded from **Data.gov.sg**.\n        -   **Eldercare** data is a list of eldercare in Singapore. It is in shapefile format.\n        -   **Hawker Centre** data is a list of hawker centres in Singapore. It is in geojson format.\n        -   **Parks** data is a list of parks in Singapore. It is in geojson format.\n        -   **Supermarket** data is a list of supermarkets in Singapore. It is in geojson format.\n        -   **CHAS clinics** data is a list of CHAS clinics in Singapore. It is in geojson format.\n        -   **Childcare service** data is a list of childcare services in Singapore. It is in geojson format.\n        -   **Kindergartens** data is a list of kindergartens in Singapore. It is in geojson format.\n    -   Downloaded from **Datamall.lta.gov.sg**.\n        -   **MRT** data is a list of MRT/LRT stations in Singapore with the station names and codes. It is in shapefile format.\n        -   **Bus stops** data is a list of bus stops in Singapore. It is in shapefile format.\n-   **Locational factors without geographic coordinates**:\n    -   Downloaded from **Data.gov.sg**.\n        -   **Primary school** data is extracted from the list on General information of schools from data.gov portal. It is in csv format.\n    -   Retrieved/Scraped from **other sources**\n        -   **CBD** coordinates obtained from Google.\n        -   **Shopping malls** data is a list of Shopping malls in Singapore obtained from [Wikipedia](https://en.wikipedia.org/wiki/List_of_shopping_malls_in_Singapore).\n        -   **Good primary schools** is a list of primary schools that are ordered in ranking in terms of popularity and this can be found at [Local Salary Forum](https://www.salary.sg/2021/best-primary-schools-2021-by-popularity).\n\n## 11.3 Installing and Loading R packages\n\nThis code chunk performs 3 tasks:\n\n-   A list called packages will be created and will consists of all the R packages required to accomplish this exercise.\n-   Check if R packages on package have been installed in R and if not, they will be installed.\n-   After all the R packages have been installed, they will be loaded.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, spdep, GWmodel, SpatialML, \n               tmap, rsample, Metrics, tidyverse)\n```\n:::\n\n\n## 11.4 Preparing Data\n\n### 11.4.1 Reading data file to rds\n\nReading the input data sets. It is in simple feature data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmdata <- read_rds(\"data/model/mdata.rds\")\n```\n:::\n\n\n### 11.4.2 Data Sampling\n\nThe entire data are split into training and test data sets with 65% and 35% respectively by using *initial_split()* of **rsample** package. rsample is one of the package of tigymodels.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nresale_split <- initial_split(mdata, \n                              prop = 6.5/10,)\ntrain_data <- training(resale_split)\ntest_data <- testing(resale_split)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(train_data, \"data/model/train_data.rds\")\nwrite_rds(test_data, \"data/model/test_data.rds\")\n```\n:::\n\n\n## 11.5 Computing Correlation Matrix\n\nBefore loading the predictors into a predictive model, it is always a good practice to use correlation matrix to examine if there is sign of multicolinearity.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmdata_nogeo <- mdata %>%\n  st_drop_geometry()\ncorrplot::corrplot(cor(mdata_nogeo[, 2:17]), \n                   diag = FALSE, \n                   order = \"AOE\",\n                   tl.pos = \"td\", \n                   tl.cex = 0.5, \n                   method = \"number\", \n                   type = \"upper\")\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex11_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n::: callout-note\nThe correlation matrix above shows that all the correlation values are below 0.8. Hence, there is no sign of multicolinearity.\n:::\n\n## 11.6 Retrieving the Stored Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_data <- read_rds(\"data/model/train_data.rds\")\ntest_data <- read_rds(\"data/model/test_data.rds\")\n```\n:::\n\n\n## 11.7 Building a non-spatial multiple linear regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprice_mlr <- lm(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                data=train_data)\nsummary(price_mlr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + \n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + \n    PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              107601.073  10601.261  10.150  < 2e-16 ***\nfloor_area_sqm             2780.698     90.579  30.699  < 2e-16 ***\nstorey_order              14299.298    339.115  42.167  < 2e-16 ***\nremaining_lease_mths        344.490      4.592  75.027  < 2e-16 ***\nPROX_CBD                 -16930.196    201.254 -84.124  < 2e-16 ***\nPROX_ELDERLYCARE         -14441.025    994.867 -14.516  < 2e-16 ***\nPROX_HAWKER              -19265.648   1273.597 -15.127  < 2e-16 ***\nPROX_MRT                 -32564.272   1744.232 -18.670  < 2e-16 ***\nPROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\nPROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\nPROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\nWITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  < 2e-16 ***\nWITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  < 2e-16 ***\nWITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\nWITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61650 on 10320 degrees of freedom\nMultiple R-squared:  0.7373,\tAdjusted R-squared:  0.737 \nF-statistic:  2069 on 14 and 10320 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(price_mlr, \"chap14/data/model/price_mlr.rds\" ) \n```\n:::\n\n\n## 11.8 Preparing coordinates data\n\n### 11.8.1 Extracting coordinates data\n\nThe code chunk below extract the x,y coordinates of the full, training and test data sets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoords <- st_coordinates(mdata)\ncoords_train <- st_coordinates(train_data)\ncoords_test <- st_coordinates(test_data)\n```\n:::\n\n\nBefore continue, we write all the output into rds for future used.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoords_train <- write_rds(coords_train, \"data/model/coords_train.rds\" )\ncoords_test <- write_rds(coords_test, \"data/model/coords_test.rds\" )\n```\n:::\n\n\n### 11.8.2 Dropping geometry field\n\nFirst, we will drop geometry column of the sf data.frame by using `st_drop_geometry()` of sf package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_data <- train_data %>% \n  st_drop_geometry()\n```\n:::\n\n\n## 11.9 Calibrating Random Forest Model\n\nIn this section, you will learn how to calibrate a model to predict HDB resale price by using random forest function of [**ranger**](https://cran.r-project.org/web/packages/ranger/index.html) package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nrf <- ranger(resale_price ~ floor_area_sqm + storey_order + \n               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n               WITHIN_1KM_PRISCH,\n             data=train_data)\nrf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       731404460 \nR squared (OOB):                  0.9493789 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(rf, \"data/model/rf.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrf <- read_rds(\"data/model/rf.rds\")\nrf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       731404460 \nR squared (OOB):                  0.9493789 \n```\n\n\n:::\n:::\n\n\n## 11.10 Calibrating Geographical Random Forest Model\n\nIn this section, you will learn how to calibrate a model to predict HDB resale price by using `grf()` of [**SpatialML**](https://cran.r-project.org/web/packages/ranger/index.html) package.\n\n### 11.10.1 Calibrating using training data\n\nThe code chunk below calibrate a geographic ranform forest model by using `grf()` of **SpatialML** package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\ngwRF_adaptive <- grf(formula = resale_price ~ floor_area_sqm + storey_order +\n                       remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +\n                       PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +\n                       PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                       WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                       WITHIN_1KM_PRISCH,\n                     dframe=train_data, \n                     bw=55,\n                     kernel=\"adaptive\",\n                     coords=coords_train)\n```\n:::\n\n\nLet's save the model output by using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(gwRF_adaptive, \"data/model/gwRF_adaptive.rds\")\n```\n:::\n\n\nThe code chunk below can be used to retrieve the save model in future.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngwRF_adaptive <- read_rds(\"data/model/gwRF_adaptive.rds\")\n```\n:::\n\n\n### 11.10.2 Predicting by using test data\n\n#### 11.10.2.1 Preparing the test data\n\nThe code chunk below will be used to combine the test data with its corresponding coordinates data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_data <- cbind(test_data, coords_test) %>%\n  st_drop_geometry()\n```\n:::\n\n\n#### 11.10.2.2 Predicting with test data\n\nNext, `predict.grf()` of spatialML package will be used to predict the resale value by using the test data and gwRF_adaptive model calibrated earlier.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngwRF_pred <- predict.grf(gwRF_adaptive, \n                           test_data, \n                           x.var.name=\"X\",\n                           y.var.name=\"Y\", \n                           local.w=1,\n                           global.w=0)\n```\n:::\n\n\nBefore moving on, let us save the output into rds file for future use.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGRF_pred <- write_rds(gwRF_pred, \"data/model/GRF_pred.rds\")\n```\n:::\n\n\n#### 11.10.2.3 Converting the predicting output into a data frame\n\nThe output of the `predict.grf()` is a vector of predicted values. It is wiser to convert it into a data frame for further visualisation and analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGRF_pred <- read_rds(\"data/model/GRF_pred.rds\")\nGRF_pred_df <- as.data.frame(GRF_pred)\n```\n:::\n\n\nIn the code chunk below, `cbind()` is used to append the predicted values onto test_datathe\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_data_p <- cbind(test_data, GRF_pred_df)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(test_data_p, \"data/model/test_data_p.rds\")\n```\n:::\n\n\n### 11.10.3 Calculating Root Mean Square Error\n\nThe root mean square error (RMSE) allows us to measure how far predicted values are from observed values in a regression analysis. In the code chunk below, rmse() of Metrics package is used to compute the RMSE.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrmse(test_data_p$resale_price, \n     test_data_p$GRF_pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 27302.9\n```\n\n\n:::\n:::\n\n\n### 11.10.4 Visualising the predicted values\n\nAlternatively, scatterplot can be used to visualise the actual resale price and the predicted resale price by using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = test_data_p,\n       aes(x = GRF_pred,\n           y = resale_price)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex11_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n::: callout-note\nA better predictive model should have the scatter point close to the diagonal line. The scatter plot can be also used to detect if any outliers in the model.\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}