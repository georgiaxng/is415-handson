---
title: "Take Home Exercise 3"
author: "Georgia Ng"
date: "October 17, 2024"
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  warning: false
  freeze: true
  cache: true
format:
  html:
    code-fold: false
    code-summary: "Click to view the code"
    embed-resources: true
---

# 1. Overview

## 1.1 Introduction

## 1.2 My Responsibilities

-   Data Preparation, Preprocessing

## 1.3 Importing Packages

Here, we have loaded the following packages:

```{r}
pacman::p_load(sf, sfdep, tmap, tidyverse, RColorBrewer, ggplot2, spatstat, jsonlite, units, matrixStats, httr)
```

# 2. The Data

For this project, we will be using the following data sets.

-   Singapore Rental Flat Prices (Jan-17 to Sep-24) from data.gov.sg

-   Master Plan 2014 Subzone Boundary (Web) from data.gov.sg

-   Hawker Centres Dataset from [data.gov.sg](https://data.gov.sg/datasets?formats=GEOJSON%7CKML%7CSHP%7CKMZ&sort=relevancy&page=1&resultId=d_4a086da0a5553be1d89383cd90d07ecd)

-   Kindergarten, Childcare Datasets from [OneMap API](https://www.onemap.gov.sg/apidocs/)

-   Bus Stops Location, MRT/ LRT Locations from [LTA Data Mall](https://datamall.lta.gov.sg/content/datamall/en/search_datasets.html?searchText=bus%20stop)

-   Shopping Mall Coordinates through wikipedia and webscraping with the coordinates retrieved through OneMap API

## 2.1 Importing Geospatial Data

### 2.1.1 Importing Singapore Subzone Boundaries

The code chunk below is used to import *MP_SUBZONE_WEB_PL* shapefile by using `st_read()` of **sf**packages.

```{r}
mpsz_sf <- st_read(dsn = "data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP/", layer = "MP14_SUBZONE_WEB_PL")
write_rds(mpsz_sf, 'data/rds/mpsz_sf.rds')
```

```{r}
st_crs(mpsz_sf)
```

#### 2.1.1.1 Checking Validity of Geometries

Using st_is_valid, we can check to see whether all the polygons are valid or not. From the results, we can see a total of 9 not valid.

```{r}
# checks for the number of geometries that are invalid
length(which(st_is_valid(mpsz_sf) == FALSE))
```

To rectify this, we can use `st_make_valid()` to correct these invalid geometries as demonstrated in the code chunk below.

```{r}
mpsz_sf <- st_make_valid(mpsz_sf)
length(which(st_is_valid(mpsz_sf) == FALSE))
```

Here is a plot of Singapore.

```{r}
plot(mpsz_sf)
```

### 2.1.2 Importing Kindergartens

```{r}
#| code-fold: true
kindergarten_json <- fromJSON("data/geospatial/kindergartens.json")

kindergarten_cleaned <- kindergarten_json$SrchResults[-1, ]

kindergarten_df <- data.frame(
  NAME = kindergarten_cleaned$NAME,
  latitude = sapply(kindergarten_cleaned$LatLng, function(x) as.numeric(unlist(strsplit(x, ","))[1])),
  longitude = sapply(kindergarten_cleaned$LatLng, function(x) as.numeric(unlist(strsplit(x, ","))[2]))
)

kindergarten_sf <- kindergarten_df %>%
  st_as_sf(coords = c("longitude", "latitude"), crs=4326) %>%
  st_transform(crs = 3414)
```

```{r}
head(kindergarten_sf)
```

### 2.1.3 Importing Childcare

```{r}
#| code-fold: true
childcare_json <- fromJSON("data/geospatial/childcare.json")

childcare_cleaned <- childcare_json$SrchResults[-1, ]

childcare_df <- data.frame(
  NAME = childcare_cleaned$NAME,
  latitude = sapply(childcare_cleaned$LatLng, function(x) as.numeric(unlist(strsplit(x, ","))[1])),
  longitude = sapply(childcare_cleaned$LatLng, function(x) as.numeric(unlist(strsplit(x, ","))[2]))
)

childcare_sf <- childcare_df %>%
  st_as_sf(coords = c("longitude", "latitude"), crs=4326) %>%
  st_transform(crs = 3414)
```

```{r}
head(childcare_sf)
```

### 2.1.4 Importing Hawker Centre

Similarly here, we will use `st_read` to read the geojson information, however since the columns values are in the format of \`\<th\></th>\` etc we will need to use a regex which is what we have done below to extract the name of the hawker centres.

```{r}
#| code-fold: true
hawker_sf <- st_read('data/geospatial/HawkerCentresGEOJSON.geojson')
# Function to extract name from description
extract_name <- function(description) {
  if (!is.na(description)) {
    # Use regular expression to extract the NAME 
    name <- sub(".*<th>NAME</th> <td>(.*?)</td>.*", "\\1", description)
    if (name == description) {
      return(NA)  # Return NA if no match is found
    }
    return(name)
  } else {
    return(NA) 
  }
}

# Apply the extraction function to every row
hawker_sf <- hawker_sf %>%
  mutate(Name = sapply(Description, extract_name)) %>% select (-Description)
```

```{r}
head(hawker_sf)
```

As shown above, we can see that the geographic coordinate system for the hawker dataset is in WGS84 and has XYZ coordinates, among which contains the Z-coordinates we do not need. Thus, we can use `st_zm()` to remove the Z-coordinate and project it to the SVY21 coordiate system using `st_transform()`.

```{r}
hawker_sf <- st_zm(hawker_sf) %>%
  st_transform(crs = 3414)

head(hawker_sf)
```

```{r}
#| code-fold: true
tmap_mode('plot')
tm_shape(mpsz_sf) +
  tm_polygons()+
  tm_shape(hawker_sf) +
  tm_dots(col='red')
```

### 2.1.5 Importing Bus Stops

```{r}
busstop_sf <- st_read(dsn = "data/geospatial/BusStopLocation_Jul2024/", layer = "BusStop")%>%
  st_transform(crs = 3414)
```

```{r}
head(busstop_sf)
```

### 2.1.6 Importing Shopping Malls

```{r}
shoppingmall_sf <- read_csv('data/geospatial/shopping_mall_coordinates.csv') %>%
  st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs=4326) %>%
  st_transform(crs = 3414)
```

```{r}
head(shoppingmall_sf)
```

### 2.1.7 Importing MRT

```{r}
mrt_sf <- st_read(dsn = "data/geospatial/TrainStation_Jul2024/", layer = "RapidTransitSystemStation")
```

Having imported the dataset, we will now need to check for both invalid geometries and NA values before proceeding. The chunk of code detects not only these but also resolves it.

```{r}
# Check for invalid geometries and NA values
validity_checks <- st_is_valid(mrt_sf, reason = TRUE)

# Identify indices with NA
na_indices <- which(is.na(validity_checks))

# Filter out rows with NA values from the mrt object
mrt_sf <- mrt_sf[-na_indices, ]

# Verify the mrt object no longer contains invalid geometries
any(is.na(sf::st_is_valid(mrt_sf)))
```

Here we use `st_transform()` to convert it to the SVY21 Coordinates System of CRS code 3414.

```{r}
mrt_sf <- mrt_sf %>%
  st_transform(crs = 3414)
```

```{r}
tmap_mode('plot')
tm_shape(mpsz_sf)+
  tm_polygons() +
  tm_shape(mrt_sf) +
  tm_dots(col='red')
```

### 2.1.8 Importing Primary School

This chunk of code imports the primary school dataset from data.gov.sg and uses the `select()` function to select the relevant columns through the input of the column numbers.

```{r}
primarysch_df = read_csv('data/geospatial/Generalinformationofschools.csv') %>% filter(mainlevel_code =='PRIMARY') %>% select(1,3,4)
```

#### 2.1.8.1 Geocoding Primary School Data using OneMap API

```{r}
#| code-fold: true
geocode <- function(address, postal) {
  base_url <- "https://www.onemap.gov.sg/api/common/elastic/search"
  query <- list("searchVal" = address,
                "postal" = postal,
                "returnGeom" = "Y",
                "getAddrDetails" = "N",
                "pageNum" = "1")
  
  res <- GET(base_url, query = query)
  restext<-content(res, as="text")
  
  output <- fromJSON(restext)  %>% 
    as.data.frame %>%
    select(results.LATITUDE, results.LONGITUDE)

  return(output)
}
```

```{r}
#| code-fold: true
#| eval: false
primarysch_df$LATITUDE <- 0
primarysch_df$LONGITUDE <- 0

for (i in 1:nrow(primarysch_df)){
  temp_output <- geocode(primarysch_df[i, 2], primarysch_df[i, 3])
  print(i)
  
  primarysch_df$LATITUDE[i] <- temp_output$results.LATITUDE
  primarysch_df$LONGITUDE[i] <- temp_output$results.LONGITUDE
}
write_rds(primarysch_df, 'data/rds/geocoded_primarysch.rds')
```

As shown below, using `head()` we can see that the new columns for lat and long has been added with the values fetched using the OneMap API.

```{r}
head(primarysch_df)
```

Using `read_rds`, we can access the already processed and geocoded data from rds without needing to run through the geocoding function again. Since the data is in the WGS coordinate system, we can use `st_transform()` to project it to the `SVY21` coordinate system we will be using.

```{r}
primarysch_df <- read_rds('data/rds/geocoded_primarysch.rds')
primarysch_sf <- primarysch_df %>%
  st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs=4326) %>%
  st_transform(crs = 3414)
```

```{r}
#| code-fold: true
tmap_mode('plot')
tm_shape(mpsz_sf)+
  tm_polygons() +
  tm_shape(primarysch_sf) +
  tm_dots(col='red')
```

### 2.1.9 Inferring CBD
Finally, let us factor in the proximity to the Central Business District - in the Downtown Core. For this, let us take the coordinates of Downtown Core to be the coordinates of the CBD:
```{r}
lat <- 1.287953
lng <- 103.851784

cbd_sf <- data.frame(lat, lng) %>%
  st_as_sf(coords = c("lng", "lat"), crs=4326) %>%
  st_transform(crs=3414)
```


## 2.2 Importing Aspatial Data

### 2.2.1 Importing Rental Flat

The code chunk below is used to import the rental

```{r}
rental_df = read_csv('data/aspatial/RentingOutofFlats2024CSV.csv')
```

To get a brief overview of existing columns of this dataset, we can use `colnames()` to do so.

```{r}
colnames(rental_df)
```

#### 2.2.1.1 Converting `rent_approval_date` to a Valid Date Format

```{r}
rental_df$rent_approval_date <- ym(rental_df$rent_approval_date)
```

#### 2.2.1.2 Filtering For Selected Time Frame

```{r}
rental_df <- rental_df %>%
  filter(year(rent_approval_date) == 2024)
```

#### 2.2.1.3 Geocoding Rental Flat Data Using OneMap API

```{r}
geocode <- function(block, streetname) {
  base_url <- "https://www.onemap.gov.sg/api/common/elastic/search"
  address <- paste(block, streetname, sep = " ")
  query <- list("searchVal" = address, 
                "returnGeom" = "Y",
                "getAddrDetails" = "N",
                "pageNum" = "1")
  
  res <- GET(base_url, query = query)
  restext<-content(res, as="text")
  
  output <- fromJSON(restext)  %>% 
    as.data.frame %>%
    select(results.LATITUDE, results.LONGITUDE)

  return(output)
}
```

```{r}
#| eval: false
rental_df$LATITUDE <- 0
rental_df$LONGITUDE <- 0

for (i in 1:nrow(rental_df)){
  temp_output <- geocode(rental_df[i, 3], rental_df[i, 4])
  print(i)
  
  rental_df$LATITUDE[i] <- temp_output$results.LATITUDE
  rental_df$LONGITUDE[i] <- temp_output$results.LONGITUDE
}
write_rds(rental_df, 'data/rds/geocoded_rental_2024.rds')
```

```{r}
rental_df <- read_rds('data/rds/geocoded_rental_2024.rds')
```

#### 2.2.1.4 CRS Adjustments

Another important step after importing the dataset is checking the coordinate system used, as seen in the result below using `st_crs()`, we can see that there is no CRS.

```{r}
st_crs(rental_df)
```

Therefore, we need to convert the longitude and latitude columns into a spatial format. Since our dataset is based in Singapore and it uses the SVY21 coordinate reference system (CRS Code: 3414), we will use the `st_transform()` function to perform the conversion and create the geometry column.

```{r}
rental_sf <- rental_df %>%
  st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs=4326) %>%
  st_transform(crs = 3414)
```

Using `st_crs()`, we can check and verify that the conversion is successful.

```{r}
st_crs(rental_sf)
```

```{r}
head(rental_sf)
```

```{r}
tmap_mode('plot')
tm_shape(mpsz_sf) +
  tm_polygons()+
  tm_shape(rental_sf) +
  tm_dots()
```

#### 2.2.1.5 Checking for NA values

This chunk of code checks the dataset for any na values in all of the columns. As shown below, there is none.

```{r}
rental_sf %>%
  summarise(across(everything(), ~ sum(is.na(.)))) -> extra_NA 
extra_NA
```

# 3. Data Wrangling

## 3.1 Removal of Redundant Columns

```{r}
# Define columns to be removed
columns_to_remove <- c("block","street_name")

# Remove columns only if they exist in the dataframe
rental_sf <- rental_sf %>%
  dplyr::select(-all_of(columns_to_remove[columns_to_remove %in% names(rental_sf)]))
```

## 3.2 Filter By Flat Type

Let us get an overview of the distributions of the housing types. As shown in the histogram, we can see that there is significantly less data for flat types like 1-room, 2-room, and executive housing.

```{r}
# Create a summary of counts for each remaining lease range
count_data <- rental_sf %>%
  group_by(flat_type) %>%
  summarise(count = n())

# Create the bar plot with labels
ggplot(count_data, aes(x = flat_type, y = count)) +
  geom_bar(stat = "identity", fill = "steelblue") + 
  geom_text(aes(label = count), vjust = -0.5, size = 4) +  # Add labels on top of the bars
  labs(title = "Count of Flat Type",
       x = "Flat Type",
       y = "Count") +
  theme_minimal()
```

Hence, we will focus on analyzing the 3-room, 4-room, and 5-room flats since they show a more substantial presence in the dataset compared to smaller flat types.

```{r}
rental_sf <- rental_sf %>% filter (flat_type == '3-ROOM' | flat_type == '4-ROOM' |flat_type == '5-ROOM' )
```

## 3.3 Calculate Number of Amenities Within 1km & Proximity To Nearest Amenity

```{r}
#| code-fold: true
calculate_amenities_and_proximity <- function(dataset1, dataset2, name_of_col_amenities, name_of_col_proximity, radius, calculateNumberOfAmenities) {
  # Calculate distance matrix
  dist_matrix <- st_distance(dataset1, dataset2) %>%
    drop_units()
  
  if (calculateNumberOfAmenities){
  # Calculate the number of amenities within the specified radius
    dataset1[[name_of_col_amenities]] <- rowSums(dist_matrix <= radius)
  }
  # Calculate the proximity to the nearest amenity
  dataset1[[name_of_col_proximity]] <- rowMins(dist_matrix)
  
  return(dataset1)
}

```

```{r}
#| code-fold: true
#| eval: false
rental_sf <- 
  calculate_amenities_and_proximity(
    rental_sf, kindergarten_sf, "no_of_kindergarten_500m", "prox_kindergarten", 500, TRUE
  ) %>%
  calculate_amenities_and_proximity(
    ., childcare_sf, "no_of_childcare_500m", "prox_childcare", 500, TRUE
  ) %>%
  calculate_amenities_and_proximity(
    ., hawker_sf, "no_of_hawker_500m", "prox_hawker", 500, TRUE
  ) %>%
  calculate_amenities_and_proximity(
    ., busstop_sf, "no_of_busstop_500m", "prox_busstop", 500, TRUE
  ) %>%
  calculate_amenities_and_proximity(
    ., shoppingmall_sf, "no_of_shoppingmall_1km", "prox_shoppingmall", 1000, TRUE
  ) %>% 
  calculate_amenities_and_proximity(
    ., mrt_sf, "x", "prox_mrt", 1000, FALSE
  ) %>%
  calculate_amenities_and_proximity(
    ., primarysch_sf, "x", "prox_prisch", 1000, FALSE
  ) %>%
  calculate_amenities_and_proximity(
    ., cbd_sf, "x", "prox_cbd", 1000, FALSE
  )


# Writing to RDS
write_rds(rental_sf,'data/rds/rental_sf.rds')

```

```{r}
rental_sf <- read_rds('data/rds/rental_sf.rds')
head(rental_sf)
```



# 4. Overview Of Dataset

```{r}
colnames(rental_sf)
```

**Explanatory Variables:**

Continuous

-   Distance to transport: `distance_to_mrt_meters`

-   Distance to amenities: `distance_to_pri_school_meters`

-   Distance to central business district: `distance_to_cbd`

-   Flat Type: `flat_type`

-   Prox_to:

-   

Categorical

-   Remaining Lease: `remaining_lease_range`

-   Storey Height: `storey_range`

**Dependent Variables:**

-   Monthly Rental: `monthly_rental`, `price_per_sqft`

# 3. Shiny Storyboard (EDA)

## 3.1 Distribution

## 3.2

# 4. Distribution

## 4.1 Categorical Variables

### 4.1.1 Housing Type

```{r}
# Create a summary of counts for each remaining lease range
count_data <- rental_sf %>%
  group_by(flat_type) %>%
  summarise(count = n())

# Create the bar plot with labels
ggplot(count_data, aes(x = flat_type, y = count)) +
  geom_bar(stat = "identity", fill = "steelblue") + 
  geom_text(aes(label = count), vjust = -0.5, size = 4) +  # Add labels on top of the bars
  labs(title = "Count of Flat Type",
       x = "Flat Type",
       y = "Count") +
  theme_minimal()
```

# Bivariate Analysis

# Correlation Matrix

# Drafts

```{r}
mpsz_sf_main <- st_union(mpsz_sf) %>%
    st_cast("POLYGON")
mpsz_sf_main <- mpsz_sf_main[c(12)]

mpsz_sf_owin <- as.owin(mpsz_sf_main)
```

```{r}
plot(mpsz_sf_owin)
```

```{r}
#| eval: false
tmap_mode('plot')
tm_shape(mpsz_sf%>% filter(PLN_AREA_N == 'ANG MO KIO'))+
  tm_polygons()+
tm_shape(rental_sf %>% filter(planning_area_ura == 'ANG MO KIO'))+
  tm_dots()
```
