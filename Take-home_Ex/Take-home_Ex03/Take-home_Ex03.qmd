---
title: "Take Home Exercise 3"
author: "Georgia Ng"
date: "October 17, 2024"
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  warning: false
  freeze: true
  cache: true
format:
  html:
    code-fold: false
    code-summary: "Click to view the code"
    embed-resources: true
---

# 1. Overview

## 1.1 Introduction

Recent MRT service breakdowns in Singapore have highlighted the importance of transportation accessibility for housing. This situation, combined with the rising influx of expats seeking rental housing, has intensified competition for well-located flats. As access to reliable public transport becomes a pivotal factor for potential renters, understanding its influence on rental prices is more critical than ever.

With this project, we aim to provide individuals looking to rent a flat with a better understanding of how transportation accessibility and other local factors affect rental prices. By leveraging Geographically Weighted Regression (GWR), our analysis will help prospective renters make informed decisions, ultimately improving their housing choices in Singaporeâ€™s dynamic urban landscape.

## 1.2 My Responsibilities

-   Data Preparation, Preprocessing
-   Explanatory Data Analysis (EDA)

## 1.3 Importing Packages

Here, we have loaded the following packages:

```{r}
pacman::p_load(sf, sfdep, tmap, tidyverse, RColorBrewer, ggplot2, spatstat, jsonlite, units, matrixStats, httr)
```

-   **sf**: Provides tools for handling and analyzing spatial vector data using simple features, facilitating operations like spatial joins, buffering, and transformations.

-   **sfdep**: Adds spatial dependency features for the `sf` package, allowing for the analysis of spatial autocorrelation and other spatial dependencies.

-   **tmap**: Used for creating and visualizing thematic maps, supporting both static and interactive mapping with various customization options.

-   **tidyverse**: A collection of R packages designed for data science, including tools for data manipulation (dplyr), visualization (ggplot2), and tidying data (tidyr).

-   **RColorBrewer**: Provides color palettes that are colorblind-friendly and designed for creating visually appealing maps and charts, suitable for categorical, sequential, and diverging data.

-   **ggplot2**: A powerful system for creating static graphics in R, based on the grammar of graphics, allowing for highly customizable visualizations.

-   **spatstat**: Offers tools for analyzing spatial point patterns, including functions for point process modeling, density estimation, and spatial statistics.

-   **jsonlite**: Simplifies the process of working with JSON data in R, enabling easy conversion between JSON and R objects for data interchange and web APIs.

-   **units**: Provides support for unit conversions in R, allowing for handling and manipulation of quantities with associated units (e.g., meters, feet) in a consistent way.

-   **matrixStats**: Offers highly optimized functions for computing statistics on matrices, particularly useful for large datasets, enabling efficient calculations for row and column operations.

-   **httr**: Simplifies working with HTTP requests in R, providing functions for sending requests, handling responses, and working with REST APIs.

# 2. The Data

For this project, we will be using the following data sets.

-   Singapore Rental Flat Prices (Jan-17 to Sep-24) from [data.gov.sg](https://data.gov.sg/datasets/d_c9f57187485a850908655db0e8cfe651/view)

-   Master Plan 2014 Subzone Boundary (Web) from [data.gov.sg](https://data.gov.sg/datasets/d_d14da225fccf921049ab64238ff473d9/view)

-   Hawker Centres Dataset from [data.gov.sg](https://data.gov.sg/datasets?formats=GEOJSON%7CKML%7CSHP%7CKMZ&sort=relevancy&page=1&resultId=d_4a086da0a5553be1d89383cd90d07ecd)

-   Kindergarten, Childcare, Primary School Datasets from [OneMap API](https://www.onemap.gov.sg/apidocs/)

-   Bus Stops Location, MRT/ LRT Locations from [LTA Data Mall](https://datamall.lta.gov.sg/content/datamall/en/search_datasets.html)

-   Shopping Malls Coordinates through wikipedia and webscraping with the coordinates retrieved through OneMap API

## 2.1 Importing Geospatial Data

### 2.1.1 Importing Singapore Subzone Boundaries

The code chunk below is used to import *MP_SUBZONE_WEB_PL* shapefile by using `st_read()` of **sf**packages.

```{r}
mpsz_sf <- st_read(dsn = "data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP/", layer = "MP14_SUBZONE_WEB_PL") %>%
  st_transform(crs = 3414)
```

Using `st_crs`, we can check the coordinate system.

```{r}
st_crs(mpsz_sf)
```

#### 2.1.1.1 Checking Validity of Geometries

Using st_is_valid, we can check to see whether all the polygons are valid or not. From the results, we can see a total of 9 not valid.

```{r}
# checks for the number of geometries that are invalid
length(which(st_is_valid(mpsz_sf) == FALSE))
```

To rectify this, we can use `st_make_valid()` to correct these invalid geometries as demonstrated in the code chunk below.

```{r}
mpsz_sf <- st_make_valid(mpsz_sf)
length(which(st_is_valid(mpsz_sf) == FALSE))
```

```{r}
#| echo: false
plot(mpsz_sf)
```

#### 2.1.1.2 Grouping By Town

Since our data is categorised by towns, it will be useful for us to group the geometries like so as well so that we can later use this to

```{r}
# Combine geometries by town in mpsz_sf
combined_town_mpsz_sf <- mpsz_sf %>%
  group_by(PLN_AREA_N) %>%  # Group by town identifier
  summarize(geometry = st_union(geometry), .groups = 'drop')

write_rds(combined_town_mpsz_sf, 'data/rds/mpsz_grped_by_town.rds')
```

### 2.1.2 Importing Kindergartens

This chunk of code imports the kindergartens data.

```{r}
kindergarten_json <- fromJSON("data/geospatial/kindergartens.json")

kindergarten_cleaned <- kindergarten_json$SrchResults[-1, ]

kindergarten_df <- data.frame(
  NAME = kindergarten_cleaned$NAME,
  latitude = sapply(kindergarten_cleaned$LatLng, function(x) as.numeric(unlist(strsplit(x, ","))[1])),
  longitude = sapply(kindergarten_cleaned$LatLng, function(x) as.numeric(unlist(strsplit(x, ","))[2]))
)

kindergarten_sf <- kindergarten_df %>%
  st_as_sf(coords = c("longitude", "latitude"), crs=4326) %>%
  st_transform(crs = 3414)

```

### 2.1.3 Importing Childcare

```{r}
childcare_json <- fromJSON("data/geospatial/childcare.json")

childcare_cleaned <- childcare_json$SrchResults[-1, ]

childcare_df <- data.frame(
  NAME = childcare_cleaned$NAME,
  latitude = sapply(childcare_cleaned$LatLng, function(x) as.numeric(unlist(strsplit(x, ","))[1])),
  longitude = sapply(childcare_cleaned$LatLng, function(x) as.numeric(unlist(strsplit(x, ","))[2]))
)

childcare_sf <- childcare_df %>%
  st_as_sf(coords = c("longitude", "latitude"), crs=4326) %>%
  st_transform(crs = 3414)
```

### 2.1.4 Importing Hawker Centre

Similarly here, we will use `st_read` to read the geojson information, however since the columns values are in the format of html code of '

<th>

<td>

' etc we will need to use a function to apply a regex expression in order to extract the name of the hawker centres.

```{r}
hawker_sf <- st_read('data/geospatial/HawkerCentresGEOJSON.geojson')
# Function to extract name from description
extract_name <- function(description) {
  if (!is.na(description)) {
    # Use regular expression to extract the NAME 
    name <- sub(".*<th>NAME</th> <td>(.*?)</td>.*", "\\1", description)
    if (name == description) {
      return(NA)  # Return NA if no match is found
    }
    return(name)
  } else {
    return(NA) 
  }
}

# Apply the extraction function to every row
hawker_sf <- hawker_sf %>%
  mutate(Name = sapply(Description, extract_name)) %>% select (-Description)
```

Here, we can see that the hawker centres are now appropriately named.

```{r}
#| echo: false
head(hawker_sf)
```

As shown above, we can see that the geographic coordinate system for the hawker dataset is in WGS84 and has XYZ coordinates, among which contains the Z-coordinates we do not need. Thus, we can use `st_zm()` to remove the Z-coordinate and project it to the SVY21 coordiate system using `st_transform()`.

```{r}
hawker_sf <- st_zm(hawker_sf) %>%
  st_transform(crs = 3414)

head(hawker_sf)
```

### 2.1.5 Importing Bus Stops

Here we are importing the bus stop locations using `st_read` and also converting it to the SVY21 coordinate system.

```{r}
busstop_sf <- st_read(dsn = "data/geospatial/BusStopLocation_Jul2024/", layer = "BusStop")%>%
  st_transform(crs = 3414)
```

### 2.1.6 Importing Shopping Malls

Here we are importing the shopping mall locations using `read_csv` and also converting it to the SVY21 coordinate system.

```{r}
shoppingmall_sf <- read_csv('data/geospatial/shopping_mall_coordinates.csv') %>%
  st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs=4326) %>%
  st_transform(crs = 3414)
```

### 2.1.7 Importing MRT

Here we are importing the mrt locations using `st_read`.

```{r}
mrt_sf <- st_read(dsn = "data/geospatial/TrainStation_Jul2024/", layer = "RapidTransitSystemStation")
```

Having imported the dataset, we will now need to check for both invalid geometries and NA values before proceeding. The chunk of code below detects not only these but also resolves it. The final printed result shows that all geometries are now valid.

```{r}
# Check for invalid geometries and NA values
validity_checks <- st_is_valid(mrt_sf, reason = TRUE)

# Identify indices with NA
na_indices <- which(is.na(validity_checks))

# Filter out rows with NA values from the mrt object
mrt_sf <- mrt_sf[-na_indices, ]

# Verify the mrt object no longer contains invalid geometries
any(is.na(sf::st_is_valid(mrt_sf)))
```

Here we use `st_transform()` to convert it to the SVY21 Coordinates System of CRS code 3414.

```{r}
mrt_sf <- mrt_sf %>%
  st_transform(crs = 3414)
```

### 2.1.8 Importing Primary School

This chunk of code imports the primary school dataset from data.gov.sg and uses the `select()` function to select the relevant columns through the input of the column numbers.

```{r}
primarysch_df = read_csv('data/geospatial/Generalinformationofschools.csv') %>% filter(mainlevel_code =='PRIMARY') %>% select(1,3,4)
```

#### 2.1.8.1 Geocoding Primary School Data using OneMap API

Since this dataset only has the addresses and not the actual coordinates, we will need to use the OneMapAPI to geocode these addresses. This chunk of code contains a function whereby the OneMapApi is called upon and returns the actual latitude and longitude of the addresses inputted.

```{r}
#| code-fold: true
geocode <- function(address, postal) {
  base_url <- "https://www.onemap.gov.sg/api/common/elastic/search"
  query <- list("searchVal" = address,
                "postal" = postal,
                "returnGeom" = "Y",
                "getAddrDetails" = "N",
                "pageNum" = "1")
  
  res <- GET(base_url, query = query)
  restext<-content(res, as="text")
  
  output <- fromJSON(restext)  %>% 
    as.data.frame %>%
    select(results.LATITUDE, results.LONGITUDE)

  return(output)
}
```

This chunk of code creates two columns for latitude and longitude and sets the default values to 0. Then it loops through every single row of the primary school dataset and calls upon the above function to populate the respective latitude and longitude values for each row.

```{r}
#| code-fold: true
#| eval: false
primarysch_df$LATITUDE <- 0
primarysch_df$LONGITUDE <- 0

for (i in 1:nrow(primarysch_df)){
  temp_output <- geocode(primarysch_df[i, 2], primarysch_df[i, 3])
  print(i)
  
  primarysch_df$LATITUDE[i] <- temp_output$results.LATITUDE
  primarysch_df$LONGITUDE[i] <- temp_output$results.LONGITUDE
}
write_rds(primarysch_df, 'data/rds/geocoded_primarysch.rds')
```

As shown below, using `head()` we can see that the new columns for lat and long has been added with the values fetched using the OneMap API.

```{r}
glimpse(primarysch_df)
```

Using `read_rds`, we can access the already processed and geocoded data from rds without needing to run through the geocoding function again. Since the data is in the WGS coordinate system, we can use `st_transform()` to project it to the `SVY21` coordinate system we will be using.

```{r}
primarysch_df <- read_rds('data/rds/geocoded_primarysch.rds')
primarysch_sf <- primarysch_df %>%
  st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs=4326) %>%
  st_transform(crs = 3414)
```

### 2.1.9 Inferring CBD

Finally, let us factor in the proximity to the Central Business District - in the Downtown Core. For this, let us take the coordinates of Downtown Core to be the coordinates of the CBD:

```{r}
lat <- 1.287953
lng <- 103.851784

cbd_sf <- data.frame(lat, lng) %>%
  st_as_sf(coords = c("lng", "lat"), crs=4326) %>%
  st_transform(crs=3414)
```

### 2.1.10 Writing Into RDS

To later use this for visualisation in our shiny app, we can use `write_rds` to store it.

```{r}
write_rds(kindergarten_sf, 'data/rds/geospatial/kindergarten_sf.rds')
write_rds(childcare_sf, 'data/rds/geospatial/childcare_sf.rds')
write_rds(hawker_sf, 'data/rds/geospatial/hawker_sf.rds')
write_rds(busstop_sf, 'data/rds/geospatial/busstop_sf.rds')
write_rds(shoppingmall_sf, 'data/rds/geospatial/shoppingmall_sf.rds')
write_rds(mrt_sf, 'data/rds/geospatial/mrt_sf.rds')
write_rds(primarysch_sf, 'data/rds/geospatial/primarysch_sf.rds')
write_rds(cbd_sf, 'data/rds/geospatial/cbd_sf.rds')
```

## 2.2 Importing Aspatial Data

### 2.2.1 Importing Rental Flat

The code chunk below is used to import the rental data from data.gov.sg.

```{r}
rental_df = read_csv('data/aspatial/RentingOutofFlats2024CSV.csv')
```

To get a brief overview of existing columns of this dataset, we can use `colnames()` to do so.

```{r}
colnames(rental_df)
```

#### 2.2.1.1 Converting `rent_approval_date` to a Valid Date Format

Since the `rent_approval_date` is in the chr format, we will want to convert it to the date format so that we can later better access and use this variable. This is done so by the `ym()` as shown in the chunk of code below.

```{r}
rental_df$rent_approval_date <- ym(rental_df$rent_approval_date)
```

#### 2.2.1.2 Filtering For 2024

Since the dataset is rather large, we want to size down our scope and instead focus on only the 2024 data, which in this case is from Jan 2024 to Sep 2024.

```{r}
rental_df <- rental_df %>%
  filter(year(rent_approval_date) == 2024)
```

#### 2.2.1.3 Geocoding Rental Flat Data Using OneMap API

Like the primary school data, we face the similar problem here thus we will need to go through the geocoding process similarly to what we have done above. The geocoding function:

```{r}
#| code-fold: true
geocode <- function(block, streetname) {
  base_url <- "https://www.onemap.gov.sg/api/common/elastic/search"
  address <- paste(block, streetname, sep = " ")
  query <- list("searchVal" = address, 
                "returnGeom" = "Y",
                "getAddrDetails" = "N",
                "pageNum" = "1")
  
  res <- GET(base_url, query = query)
  restext<-content(res, as="text")
  
  output <- fromJSON(restext)  %>% 
    as.data.frame %>%
    select(results.LATITUDE, results.LONGITUDE)

  return(output)
}
```

This chunk of code then calls upon the above function for every single row of the `rental_df` and writes it to the rds.

```{r}
#| eval: false
rental_df$LATITUDE <- 0
rental_df$LONGITUDE <- 0

for (i in 1:nrow(rental_df)){
  temp_output <- geocode(rental_df[i, 3], rental_df[i, 4])
  print(i)
  
  rental_df$LATITUDE[i] <- temp_output$results.LATITUDE
  rental_df$LONGITUDE[i] <- temp_output$results.LONGITUDE
}
write_rds(rental_df, 'data/rds/geocoded_rental_2024.rds')
```

Without needing to run the above time-consuming method yet again, we can just read the data from the rds here.

```{r}
rental_df <- read_rds('data/rds/geocoded_rental_2024.rds')
```

#### 2.2.1.4 CRS Adjustments

Another important step after importing the dataset is checking the coordinate system used, as seen in the result below using `st_crs()`, we can see that there is no CRS stated for `rental_df`.

```{r}
st_crs(rental_df)
```

Therefore, we need to convert the longitude and latitude columns into a spatial format. Since our dataset is based in Singapore and it uses the SVY21 coordinate reference system (CRS Code: 3414), we will use the `st_transform()` function to perform the conversion and create the geometry column.

```{r}
rental_sf <- rental_df %>%
  st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs=4326) %>%
  st_transform(crs = 3414)
```

Using `st_crs()`, we can check and verify that the conversion is successful.

```{r}
st_crs(rental_sf)
```

```{r}
#| echo: false
head(rental_sf)
```

#### 2.2.1.5 Checking for NA values

This chunk of code checks the dataset for any na values in all of the columns. As shown below, there is none.

```{r}
rental_sf %>%
  summarise(across(everything(), ~ sum(is.na(.)))) -> extra_NA 
extra_NA
```

# 3. Data Wrangling

## 3.1 Removal of Redundant Columns

To increase efficiency and reduce the data size, we can remove columns we do not need like the `block` and `street_name` in which we have already utilised previously and now have no use for.

```{r}
# Define columns to be removed
columns_to_remove <- c("block","street_name")

# Remove columns only if they exist in the dataframe
rental_sf <- rental_sf %>%
  dplyr::select(-all_of(columns_to_remove[columns_to_remove %in% names(rental_sf)]))
```

## 3.2 Filter By Flat Type

Let us get an overview of the distributions of the housing types. As shown in the histogram, we can see that there is significantly less data for flat types like 1-room, 2-room, and executive housing.

```{r}
# Create a summary of counts for each remaining lease range
count_data <- rental_sf %>%
  group_by(flat_type) %>%
  summarise(count = n())

# Create the bar plot with labels
ggplot(count_data, aes(x = flat_type, y = count)) +
  geom_bar(stat = "identity", fill = "steelblue") + 
  geom_text(aes(label = count), vjust = -0.5, size = 4) +  # Add labels on top of the bars
  labs(title = "Count of Flat Type",
       x = "Flat Type",
       y = "Count") +
  theme_minimal()
```

Hence, we will focus on analyzing the 3-room, 4-room, and 5-room flats since they show a more substantial presence in the dataset compared to smaller flat types.

```{r}
rental_sf <- rental_sf %>% filter (flat_type == '3-ROOM' | flat_type == '4-ROOM' |flat_type == '5-ROOM' )
```

## 3.3 Adding Region to Rental Data

This chunk of code performs a left join with `mpsz_sf`to categorise the different flats into different regions in order to better understand the rental trends.

### 3.3.1 Left Joining with `mpsz_sf`

```{r}
# Perform the left join by dropping the geometry from 'datab' and only bringing in 'region_n'
rental_sf <- rental_sf %>%
  left_join(st_drop_geometry(mpsz_sf) %>% select(PLN_AREA_N, REGION_N) %>% distinct(PLN_AREA_N, .keep_all = TRUE), 
            by = c("town" = "PLN_AREA_N"))
```

### 3.3.2 Identifying Rows with NA values

Then, let's perform a check to see if any of the rows have na values in the newly created column and display it. As shown here we can see that there are multiple rows in which the `town` column was unable to find a matching value in the `mpsz_sf` `PLN_AREA_N` column.

```{r}
rental_sf_with_na <- rental_sf %>%
  filter(is.na(REGION_N))

rental_sf_with_na
```

Using unique, we can identify the `town` values of these problematic rows and also the available regions in `mpsz_sf` so that we have a brief idea of what are the possible values we can later use. In particular, the problematic values are 'Kallang/Whampoa' and 'Central'.

```{r}
unique (rental_sf_with_na$town)
unique(mpsz_sf$REGION_N)
```

Since the value is Kallang/Whampoa, let's try to find the region of either Kallang or Whampoa through the filter()\` function.

```{r}
test <- mpsz_sf%>% filter(PLN_AREA_N == 'KALLANG' | PLN_AREA_N == 'WHAMPOA') %>% select(PLN_AREA_N,REGION_N)
test
```

While we can't find a match for Whampoa, we can see that Kallang falls under the Central Region. From the naming, we can also make the deduction that the town 'Central' likely falls under the same region. Thus by using a `if_else` statement we can assign the region Central Region to these towns.

```{r}
rental_sf <- rental_sf %>%
  mutate(REGION_N = if_else(town == 'CENTRAL' | town == 'KALLANG/WHAMPOA', 'CENTRAL REGION', REGION_N))
```

Let us also rename the column to standardise the namings.

```{r}
rental_sf <- rental_sf %>% rename(region = REGION_N)
```

## 3.4 Calculate Number of Facilities Within A Certain Distance & Proximity To Nearest Facility

Since the number of facilities within range and proximity to certain facilities are some of the most important factors of rental prices, it is important for us to include that in our analysis as well. Thus to do so we have the below function to made these calculations based on the locations of the different facilities' datasets we have imported compared with the individual rental flats themselves.

::: callout-note
Note: the calculateNumberOffacilities is a parameter used to indicate if the calculation of facilities for a particular facility is required.
:::

```{r}
#| code-fold: true
calculate_facilities_and_proximity <- function(dataset1, dataset2, name_of_col_facilities, name_of_col_proximity, radius, calculateNumberOfFacilities) {
  # Calculate distance matrix
  dist_matrix <- st_distance(dataset1, dataset2) %>%
    drop_units()
  
  if (calculateNumberOfFacilities){
  # Calculate the number of facilities within the specified radius
    dataset1[[name_of_col_facilities]] <- rowSums(dist_matrix <= radius)
  }
  # Calculate the proximity to the nearest facility
  dataset1[[name_of_col_proximity]] <- rowMins(dist_matrix)
  
  return(dataset1)
}

```

The below chunk of code calls upon the `calculate_facilities_and_proximity()` based on the different parameters stated for each facility. We indicated for the mrt and primary school to not be included in the calculations for the count within a certain radius as the distance to such facilities has way more importance than the actual count of it which is usually one within a certain range since these facilities are more spread out.

```{r}
#| code-fold: true
#| eval: false
rental_sf <- 
  calculate_facilities_and_proximity(
    rental_sf, kindergarten_sf, "no_of_kindergarten_500m", "prox_kindergarten", 500, TRUE
  ) %>%
  calculate_facilities_and_proximity(
    ., childcare_sf, "no_of_childcare_500m", "prox_childcare", 500, TRUE
  ) %>%
  calculate_facilities_and_proximity(
    ., hawker_sf, "no_of_hawker_500m", "prox_hawker", 500, TRUE
  ) %>%
  calculate_facilities_and_proximity(
    ., busstop_sf, "no_of_busstop_500m", "prox_busstop", 500, TRUE
  ) %>%
  calculate_facilities_and_proximity(
    ., shoppingmall_sf, "no_of_shoppingmall_1km", "prox_shoppingmall", 1000, TRUE
  ) %>% 
  calculate_facilities_and_proximity(
    ., mrt_sf, "x", "prox_mrt", 1000, FALSE
  ) %>%
  calculate_facilities_and_proximity(
    ., primarysch_sf, "x", "prox_prisch", 1000, FALSE
  ) %>%
  calculate_facilities_and_proximity(
    ., cbd_sf, "x", "prox_cbd", 1000, FALSE
  )


# Writing to RDS
write_rds(rental_sf,'data/rds/rental_sf.rds')

```

Likewise, to skip the whole time-consuming process, we can instead read the rds data using the below code.

```{r}
rental_sf <- read_rds('data/rds/rental_sf.rds')
glimpse(rental_sf)
```

# 4. Overview Of Dataset

Below is an overview of what our dataset currently consists of.

```{r}
colnames(rental_sf)
```

**Dependent Variables:**

-   Monthly Rental: `monthly_rent`

**Explanatory Variables:**

Continuous

-   Prox\_ \[distance to closest\]: kindergarten, childcare, hawker, bus stops, shopping mall, mrt, primary schools, cbd

-   Count of xx within xx distance: `no_of_kindergarten_500m`, `no_of_childcare_500m`, `no_of_hawker_500m`, `no_of_busstop_500m`, `no_of_shoppingmall_1km`

Categorical

-   Flat Type: `flat_type`

-   Town: `town`

-   Region: `region`

# 5. Shiny Storyboard (EDA)

Since I am in charge of the exploratory data analysis. sections for my group's shiny app, here is a brief overview of the storyboard of the visualisations we will be doing. This is not final and only serves as a guideline of how our app will look like.

## 5.1 Histogram

![](images/clipboard-2175309603.png)

## 5.2 Choropleth Map

![](images/clipboard-544302462.png)

## 5.3 Scatterplot

![](images/clipboard-186348156.png)

## 5.4 Locations of Interest

![](images/clipboard-755984476.png)

# 6. Histograms

Continuous

| Options                       | Values                            |
|-------------------------------|-----------------------------------|
| Filter                        | `month_year`, `flat_type`, `town` |
| Choose Variables for Plotting | `monthly_rent`, `prox_hawker` etc |

Categorical

| Options     | Values                     |
|-------------|----------------------------|
| X variables | `flat_type`, `region`      |
| Y variables | `frequency`, `median_rent` |

## 6.1 Categorical Variables

### 6.1.1 Plotting by count of data

```{r}
#| code-fold: true
# Create a summary of counts for each remaining lease range
count_data <- rental_sf %>%
  group_by(flat_type) %>%
  summarise(count = n())

# Create the bar plot with labels
ggplot(count_data, aes(x = flat_type, y = count)) +
  geom_bar(stat = "identity", fill = "steelblue") + 
  geom_text(aes(label = count), vjust = -0.5, size = 4) +  # Add labels on top of the bars
  labs(title = "Count of Flat Type",
       x = "Flat Type",
       y = "Count") +
  theme_minimal()
```

### 6.1.2 Plotting By Median Rental Price

```{r}
#| code-fold: true
# Get Median Rent Data
median_rent_data <- rental_sf %>%
  group_by(flat_type) %>%
  summarise(median_rent = median(monthly_rent, na.rm = TRUE),
        .groups = 'drop'
  )

# Create the bar plot with labels
ggplot(median_rent_data, aes(x = flat_type, y = median_rent)) +
  geom_bar(stat = "identity", fill = "steelblue") + 
  geom_text(aes(label = median_rent), vjust = -0.5, size = 4) +  # Add labels on top of the bars
  labs(title = "Median Rent of Different Flat Type",
       x = "Flat Type",
       y = "Median Rent") +
  theme_minimal()
```

## 6.2 Continuous Variables

```{r}
#| code-fold: true
selected_month = "2024 Jan"
selected_flat_type = '3-ROOM'
selected_town = 'ANG MO KIO'
selected_plot_variable = 'monthly_rent'
bin_number = 10
# Filter based on params
histo_filtered_rental_sf <- rental_sf %>%
      mutate(year_month = format(rent_approval_date, "%Y %b")) %>%
      filter (if (selected_month == "2024 Jan to Sep") {
        TRUE  # No additional filtering by month
      } else {
        format(rent_approval_date, "%Y %b") == selected_month  # Filter by selected year-month
      }) %>%
      filter(flat_type == selected_flat_type) %>%
      filter(town == selected_town)

# Create the histogram with labels
ggplot(histo_filtered_rental_sf,
                  aes_string(x = selected_plot_variable)) +
        geom_histogram(
          bins = bin_number,
          fill = "blue",
          color = "black"
        ) +  
        labs(
          title = paste("Histogram of", selected_plot_variable),
          x = selected_plot_variable,
          y = "Frequency"
        )
```

# 7. Choropleth Mapping

| Options                  | Values                                 |
|--------------------------|----------------------------------------|
| Filter                   | `month_year` and `flat_type`           |
| Plot different variables | Median Monthly Rent, Rented Flat Count |

::: callout-note
Note: As Kallang/Whampoa does not match any towns in `mpsz_sf`, we will map it to Kallang. On the other hand for the town 'Central', since we are not able to make any deduction based on this naming and it also does not match any region values in `mpsz_sf`, we can only remove it from the choropleth mapping.
:::

## 7.1 Example for Rented Flat Count

```{r}
selected_month = "2024 Jan"
selected_flat_type = '3-ROOM'
# Dealing with Kallang/Whampoa & Central town which is not present in mpsz
# Filter based on month and flat type
ch_filtered_rental_sf <- rental_sf %>%
  mutate(town = if_else(town == 'KALLANG/WHAMPOA', 'KALLANG', town)) %>%   
  filter(town != "CENTRAL") %>% 
  filter (if (selected_month == "2024 Jan to Sep") {
        TRUE  # No additional filtering by month
      } else {
        format(rent_approval_date, "%Y %b") == selected_month  # Filter by selected year-month
      }) %>%
      filter(flat_type == selected_flat_type)
  
# Create choropleth_data
choropleth_data <- ch_filtered_rental_sf  %>%
  group_by(town) %>%
  summarize(rented_count = n(), .groups = 'drop') %>%
  st_drop_geometry() %>%
  right_join(combined_town_mpsz_sf, 
            by = c("town" = "PLN_AREA_N")) %>%
  st_as_sf()  # Convert to sf object after joining

```

```{r}
tmap_mode("view")
qtm(choropleth_data, 
    fill = "rented_count")
```

## 7.2 Example of Median Monthly Rent

```{r}
selected_month = "2024 Jan"
selected_flat_type = '3-ROOM'
# Dealing with Kallang/Whampoa & Central town which is not present in mpsz
# Filter based on month and flat type
ch_filtered_rental_sf <- rental_sf %>%
  mutate(town = if_else(town == 'KALLANG/WHAMPOA', 'KALLANG', town)) %>%
  filter(town != "CENTRAL") %>%
  filter (if (selected_month == "2024 Jan to Sep") {
    TRUE  # No additional filtering by month
  } else {
    format(rent_approval_date, "%Y %b") == selected_month  # Filter by selected year-month
  }) %>%
  filter(flat_type == selected_flat_type)

# Create choropleth_data
choropleth_data <- ch_filtered_rental_sf  %>%
  group_by(town) %>%
  summarize(median_rent = median(monthly_rent, na.rm = TRUE),
            .groups = 'drop') %>%
  st_drop_geometry() %>%
  right_join(combined_town_mpsz_sf, by = c("town" = "PLN_AREA_N")) %>%
  st_as_sf()  # Convert to sf object after joining

```

```{r}
tmap_mode("view")
qtm(choropleth_data, 
    fill = "median_rent")
```

# 8 Scatterplot

For this, we will generate scatterplots for any pair of continuous variables the user chooses. Similar to the previous parts, we will also include filter options for the users to filter the data.

| Options     | Values                                          |
|-------------|-------------------------------------------------|
| X variables | any continuous, eg `monthly_rent`, `prox_mrt`   |
| Y variables | any continuous, eg `prox_hawker`, `prox_prisch` |
| Filter      | `month_year`, `flat_type`, `town`               |

```{r}
selected_month = "2024 Jan"
selected_flat_type = '3-ROOM'
selected_town = 'YISHUN'
scatter_filtered_data <- rental_sf %>%
      mutate(year_month = format(rent_approval_date, "%Y %b")) %>%
      filter (if (selected_month == "2024 Jan to Sep") {
        TRUE  # No additional filtering by month
      } else {
        format(rent_approval_date, "%Y %b") == selected_month  # Filter by selected year-month
      }) %>%
      filter(flat_type == selected_flat_type)%>%
      filter(if (selected_town == 'all') TRUE else town == selected_town)
ggplot(scatter_filtered_data,
       aes(x = monthly_rent, y = prox_hawker)) +  # Refer to columns directly
  geom_point(color = 'blue', size = 1) +
  labs(
    title = paste("Scatterplot of Monthly Rent vs. Proximity to Hawker"),
    x = "Monthly Rent",
    y = "Proximity to Hawker"
  ) +
  theme_minimal()
```

# 9 **Visualising Locations of Interest**

| Options                 | Values                                                             |
|--------------------|----------------------------------------------------|
| Filter by town          | `town`                                                             |
| Geospatial data to plot | All geospatial datasets including Kindergarten, Primary School etc |

Here is an example of how the user can visualise the locations of interest by inputting the town they want and also the categories of location (like bus stops, hawker centre locations etc).

The below example is for Bus Stops in Yishun.

```{r}
# Filter for town boundaries in mpsz_sf
specific_town_sf <- mpsz_sf %>% filter(PLN_AREA_N == 'YISHUN')

# Performing a spatial intersection
filtered_busstops <- st_intersection(busstop_sf, specific_town_sf)

# Switch to interactive map mode
tmap_mode('view')

# Plot bus stops within Yishun
tm_shape(filtered_busstops) +
  tm_dots(col = 'red')
```

# 10 Final Result

Below are the screenshots of the final results. While most of the inputs are dropdowns, I also tried incorporating other different inputs like radio and sliders to increase the variety.

## 10.1 Histogram

With a histogram, the users can see the frequency and distribution of their selected variables.

### 10.1.1 Continuous

![](images/clipboard-1713461402.png)

### 10.1.2 Categorical

![](images/clipboard-1450392771.png)

## 10.2 Choropleth Map

The choropleth map on the other hand will provide them with a quick understanding of the spatial distribution of median rent and monthly rent across various towns **in** Singapore.

![](images/clipboard-3861265493.png)

## 10.3 Scatterplot

With the scatterplot, we can easily see the relationship between pairs of variables and see how one correlates with another.

![](images/clipboard-1548578381.png)

## 10.4 Locations of Interest

With this map, we can see the locations of different locations of interest that we have used to calculate values like the proximity to the nearest locations of interest and count of locations of interest within a certain radius.

![](images/clipboard-4076469297.png)

# 11 Conclusion

For my part, I tried to include filters wherever possible so that users can narrow down the data to find **specific insights tailored to their needs**. By allowing users to filter based on criteria such as flat type, rental prices, and geographic locations, they can focus on the most relevant information for their purposes. This functionality enhances the user experience by making the data exploration process more intuitive and efficient, enabling users to uncover trends and patterns that are directly applicable to their individual interests or decision-making processes.
